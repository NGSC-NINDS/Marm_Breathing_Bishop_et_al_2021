{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import neo\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "from matplotlib import pyplot as plt\n",
    "from neo.io import Spike2IO\n",
    "import scipy\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy import stats\n",
    "import os\n",
    "import time\n",
    "\n",
    "def rsp_process(raw_sig, samp_rate):\n",
    "    \"\"\"Processing pipeline for plethysmography signal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_sig: numpy array\n",
    "        Raw respiratory signal, input from NEOIO\n",
    "    \n",
    "    samp_rate: int\n",
    "        Sampling rate in Hz.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    signals: Pandas Dataframe\n",
    "        Dataframe full of features extracted from raw signal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Neurokit2 functions for cleaning raw signal and finding peaks\n",
    "    sig_detrended = nk.signal_detrend(raw_sig)\n",
    "    sig_filtered = nk.signal_filter(sig_detrended, lowcut=.05, highcut=5, sampling_rate=samp_rate)\n",
    "    peak_signal, info = nk.rsp_peaks(sig_filtered,sampling_rate=samp_rate, amplitude_min=.05)\n",
    "\n",
    "    # Get additional parameters\n",
    "    phase = nk.rsp_phase(peak_signal, desired_length=len(raw_sig))\n",
    "    amplitude = nk.rsp_amplitude(sig_filtered, peak_signal)\n",
    "    rate = nk.signal_rate(peak_signal, sampling_rate=samp_rate, desired_length=len(raw_sig))\n",
    "\n",
    "\n",
    "    # Prepare output\n",
    "    signals = pd.DataFrame({\"RSP_Raw\": raw_sig,\n",
    "                            \"RSP_Clean\": sig_filtered,\n",
    "                            \"RSP_Amplitude\": amplitude,\n",
    "                            \"RSP_Rate\": rate})\n",
    "    signals = pd.concat([signals, phase, peak_signal], axis=1)\n",
    "    variability = nk.rsp_rrv(signals,sampling_rate=samp_rate)\n",
    "\n",
    "    return signals, variability\n",
    "\n",
    "def remove_outliers(signal):\n",
    "    \"\"\"Filters out artifact rows in signal dataframe\n",
    "    based on Rate and Amplitude values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal: pandas dataframe\n",
    "        Dataframe returned by rsp_process, should include RSP_Rate and RSP_Amplitude columns. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    cleaned_signal: pandas dataframe\n",
    "        Dataframe with rows removed that contain outlier Rate or Amplitude Values\n",
    "    \"\"\"\n",
    "    signal = signal[signal.RSP_Rate < 200]\n",
    "    signal = signal[signal.RSP_Rate > 0]\n",
    "    signal = signal[signal.RSP_Amplitude > 0]\n",
    "    cleaned_signal = signal[signal.RSP_Amplitude < 1]\n",
    "    return cleaned_signal\n",
    "\n",
    "def find_breaths(rsp, samp_rate, max_bpm=150):\n",
    "    '''Finds time and number of peaks of apnea and sniffing breathing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rsp: pandas dataframe\n",
    "        Dataframe returned by rsp_process\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    apnea_counts: int\n",
    "        number of peaks spent in apnea\n",
    "    \n",
    "    apnea_time: float\n",
    "        time spent in apnea breathing\n",
    "        \n",
    "    sniff_counts: int\n",
    "        number of peaks spent in sniff\n",
    "    \n",
    "    sniff_time: float\n",
    "        time spent in sniff breathing\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Remove interpolated values for counting breaths\n",
    "    peaks_only = rsp.groupby('RSP_Peaks').get_group(1)\n",
    "    min_bpm = peaks_only.RSP_Rate.mean() / 3 \n",
    "    # find rate of apneas per second, then multiply for rate/hour\n",
    "    apnea_rate = 3600 * len(peaks_only[peaks_only.RSP_Rate < min_bpm])/(len(rsp)/samp_rate)\n",
    "    \n",
    "    # Use interpolated values for time calculations\n",
    "    apnea_time = len(rsp[rsp.RSP_Rate < min_bpm])/samp_rate\n",
    "    \n",
    "    # same for sniffing\n",
    "    sniff_rate = 3600*len(peaks_only[(peaks_only.RSP_Rate > max_bpm) & (peaks_only.RSP_Amplitude < 1)])/(len(rsp)/samp_rate)\n",
    "    sniff_time = len(rsp[rsp.RSP_Rate > max_bpm])/samp_rate\n",
    "    \n",
    "    return apnea_rate, apnea_time, sniff_rate, sniff_time\n",
    "    \n",
    "    \n",
    "\n",
    "def file_processor(filename, events_dict, info_df, epoch_len = None, baseline_df = None, last_five=False, plot=False, debug = False):\n",
    "    \"\"\"\n",
    "    Processes csv pleth files\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "        name of the csv file \n",
    "    \n",
    "    events_dict: dict\n",
    "        dictionary of different events and their empty dictionaries\n",
    "    \n",
    "    info_df: pandas dataframe\n",
    "        dataframe from excel file that contains info about each animal\n",
    "        \n",
    "    samp_rate: int\n",
    "        Rate in Hz of sampling\n",
    "    \n",
    "    epoch_len: int\n",
    "        length of epochs in seconds that the file is chopped into\n",
    "    \n",
    "    plot: bool\n",
    "        If True, calls Neurokit's plot function on the entire event. Defaults to False\n",
    "        \n",
    "    baseline_df: pandas dataframe\n",
    "        Used for comparison to baseline during challenge to produce % change\n",
    "        \n",
    "    last_five: if True then only analyzes after 5 mins of each event\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    info_row = info_df[(info_df.ID.str.match(filename[0:4]))]\n",
    "    print(info_row.ID.values[0])\n",
    "    # Read in raw files\n",
    "    reader = Spike2IO(filename)\n",
    "    # Open block to select segment to be read\n",
    "    block = reader.read(lazy=False)[0]\n",
    "    raw_signal_vals = np.asarray(block.segments[0].analogsignals[2])\n",
    "    flat_sig = raw_signal_vals[:,0]\n",
    "    sampling_rate = block.segments[0].analogsignals[2].sampling_rate.item()\n",
    "    print(sampling_rate)\n",
    "    # Process whole signal \n",
    "    signals, sig_var = rsp_process(flat_sig, samp_rate=sampling_rate)\n",
    "    signals['Amp_norm'] = signals.RSP_Amplitude/info_row.weight.values[0]\n",
    "    \n",
    "    for event, dictionary in events_dict.items():\n",
    "        \n",
    "        # chop up signals df with values from info_df\n",
    "        event_start = int(info_row[event+'_start']) * sampling_rate\n",
    "        event_end = int(info_row[event+'_end']) * sampling_rate\n",
    "        event_signals = signals.loc[event_start:event_end, :]\n",
    "        \n",
    "        if event == 'challenge':\n",
    "            pre_signals = signals.loc[event_start - 600*sampling_rate:event_start, :]\n",
    "            post_signals = signals.loc[event_end:event_end+600*sampling_rate]\n",
    "            sig_list = [pre_signals, event_signals, post_signals]\n",
    "            epoch_len = 59.9\n",
    "        else:\n",
    "            print(event)\n",
    "            pre_signals = signals.loc[event_start-60*sampling_rate:event_start, :]\n",
    "            sig_list = [pre_signals,event_signals]\n",
    "            epoch_len = None\n",
    "        \n",
    "        sig_counter = 0\n",
    "        for key, item in dictionary.items():\n",
    "            sub_sig = sig_list[sig_counter]\n",
    "            sig_counter += 1\n",
    "\n",
    "            # Calculate augmented breath measures\n",
    "            apnea_rate, apnea_time, sniff_rate, sniff_time = find_breaths(sub_sig.reset_index(drop=True), samp_rate=sampling_rate)\n",
    "            interval_df = nk.rsp_intervalrelated(sub_sig, sampling_rate = sampling_rate)\n",
    "\n",
    "            # Put them into the appropriate df\n",
    "            item['Animal'].append(filename[:4])\n",
    "            item['RSP_Rate_Mean'].append(sub_sig.RSP_Rate.mean())\n",
    "            item['RSP_Amplitude_Mean'].append(sub_sig.Amp_norm.mean())\n",
    "            item['Ti'].append(interval_df.RSP_Phase_Duration_Inspiration.values[0])\n",
    "            item['Te'].append(interval_df.RSP_Phase_Duration_Expiration.values[0])\n",
    "            item['Ti-Te_Ratio'].append(interval_df.RSP_Phase_Duration_Ratio.values[0])\n",
    "            item['Resp_Drive'].append(sub_sig.Amp_norm.mean()/interval_df.RSP_Phase_Duration_Inspiration.values[0])\n",
    "            item['Ve'].append(sub_sig.Amp_norm.mean() * signals.RSP_Rate.mean())\n",
    "            item['Apnea_time'].append(apnea_time)\n",
    "            item['Apnea_rate'].append(apnea_rate)\n",
    "            item['Sniff_time'].append(sniff_time)\n",
    "            item['Sniff_rate'].append(sniff_rate)\n",
    "            item['RRV_SD1'].append(sig_var.RRV_SD1.loc[0])\n",
    "            item['RRV_SD2'].append(sig_var.RRV_SD2.loc[0])\n",
    "\n",
    "            if epoch_len is not None:\n",
    "                # Epoch the challenge signal\n",
    "                epochs = nk.epochs_create(sub_sig, sampling_rate=sampling_rate, epochs_end=epoch_len)\n",
    "        #         clean_epochs = {key:remove_outliers(epoch) for key,epoch in epochs.items()} \n",
    "                epoch_df = nk.rsp_intervalrelated(epochs, sampling_rate=sampling_rate)\n",
    "                if baseline_df is not None:\n",
    "                    epoch_df = find_percentchange(epoch_df, baseline_df, animal = filename[9:13])\n",
    "                # Normalize amp to weight and calc Ve\n",
    "                epoch_df['Amp_Norm'] = epoch_df.RSP_Amplitude_Mean / info_row.weight.values[0]\n",
    "                epoch_df['Ve'] = epoch_df.Amp_Norm * epoch_df.RSP_Rate_Mean\n",
    "                epoch_df['Resp_drive'] = epoch_df.Amp_Norm / epoch_df.RSP_Phase_Duration_Inspiration\n",
    "                sheet_name = str(info_row.Condition.values[0])+info_row.sex.values[0]+filename[:4]+key+'epochs'\n",
    "                print(sheet_name)\n",
    "                epoch_df.to_excel(writer, sheet_name=sheet_name)\n",
    "            \n",
    "            if debug == True:\n",
    "                return signals   \n",
    "\n",
    "    \n",
    "def find_percentchange(epoch_df, baseline_df, animal):\n",
    "    # animal name is file[9:13]\n",
    "    measures=[i for i in baseline_df.columns if 'Mean' in i or 'SD' in i]\n",
    "    animal_row = baseline_df.loc[animal==baseline_df['Animal']]\n",
    "    for x in measures: \n",
    "        base_val = float(animal_row.loc[:,x])\n",
    "        epoch_df[x+'_percent_change']= 100*(epoch_df[x] - base_val)/base_val\n",
    "    return epoch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  Amber_CO2_Oct2020.smr\n",
      "Amber\n",
      "8333.333333333334\n",
      "CO2FAmbepre_challengeepochs\n",
      "CO2FAmbechallengeepochs\n",
      "CO2FAmbepostchallengeepochs\n",
      "Processing:  Cassius_O2_Sep2020.smr\n",
      "Cassius\n",
      "8333.333333333334\n",
      "_O2MCasspre_challengeepochs\n",
      "_O2MCasschallengeepochs\n",
      "_O2MCasspostchallengeepochs\n",
      "Processing:  Chatterbox_CO2_Oct2020.smr\n",
      "Chatterbox\n",
      "8333.333333333334\n",
      "CO2MChatpre_challengeepochs\n",
      "CO2MChatchallengeepochs\n",
      "CO2MChatpostchallengeepochs\n",
      "Processing:  Datil_TA27_Aug2020_hypoxia.smr\n",
      "Datil\n",
      "10000.0\n",
      "_O2FDatipre_challengeepochs\n",
      "_O2FDatichallengeepochs\n",
      "_O2FDatipostchallengeepochs\n",
      "Processing:  Dewey_CO2_Oct2020.smr\n",
      "Dewey\n",
      "8333.333333333334\n",
      "CO2MDewepre_challengeepochs\n",
      "CO2MDewechallengeepochs\n",
      "CO2MDewepostchallengeepochs\n",
      "Processing:  Green_hypoxia_Aug_2020.smr\n",
      "Green\n",
      "10000.0\n",
      "_O2FGreepre_challengeepochs\n",
      "_O2FGreechallengeepochs\n",
      "_O2FGreepostchallengeepochs\n",
      "Processing:  Hermione_CO2_Oct2020.smr\n",
      "Hermione\n",
      "8333.333333333334\n",
      "CO2FHermpre_challengeepochs\n",
      "CO2FHermchallengeepochs\n",
      "CO2FHermpostchallengeepochs\n",
      "Processing:  Louie_O2.smr\n",
      "Louie\n",
      "10000.0\n",
      "_O2FLouipre_challengeepochs\n",
      "_O2FLouichallengeepochs\n",
      "_O2FLouipostchallengeepochs\n",
      "Processing:  Nemesis_CO2.smr\n",
      "Nemesis\n",
      "10000.0\n",
      "CO2FNemepre_challengeepochs\n",
      "CO2FNemechallengeepochs\n",
      "CO2FNemepostchallengeepochs\n",
      "Processing:  Nyx_O2.smr\n",
      "Nyx_\n",
      "10000.0\n",
      "_O2FNyx_pre_challengeepochs\n",
      "_O2FNyx_challengeepochs\n",
      "_O2FNyx_postchallengeepochs\n",
      "Processing:  Poblona_O2_Sep2020.smr\n",
      "Poblona\n",
      "8333.333333333334\n",
      "_O2MPoblpre_challengeepochs\n",
      "_O2MPoblchallengeepochs\n",
      "_O2MPoblpostchallengeepochs\n",
      "Processing:  Pollux_O2.smr\n",
      "Pollux\n",
      "10000.0\n",
      "_O2MPollpre_challengeepochs\n",
      "_O2MPollchallengeepochs\n",
      "_O2MPollpostchallengeepochs\n",
      "Processing:  Sachem_O2_Aug_2020.smr\n",
      "Sachem\n",
      "10000.0\n",
      "_O2MSachpre_challengeepochs\n",
      "_O2MSachchallengeepochs\n",
      "_O2MSachpostchallengeepochs\n",
      "Processing:  Terminator_CO2.smr\n",
      "Terminator\n",
      "10000.0\n",
      "CO2FTermpre_challengeepochs\n",
      "CO2FTermchallengeepochs\n",
      "CO2FTermpostchallengeepochs\n",
      "Processing:  Voltron_CO2.smr\n",
      "Voltron\n",
      "10000.0\n",
      "CO2MVoltpre_challengeepochs\n",
      "CO2MVoltchallengeepochs\n",
      "CO2MVoltpostchallengeepochs\n",
      "Processing:  Zeus_CO2.smr\n",
      "Zeus\n",
      "10000.0\n",
      "CO2MZeuspre_challengeepochs\n",
      "CO2MZeuschallengeepochs\n",
      "CO2MZeuspostchallengeepochs\n",
      "20210610-Chudasama_resp.xlsx  Saved!\n"
     ]
    }
   ],
   "source": [
    "info_dir = '/Users/bishopmn/Documents/Projects/Marm_breathing/Raw_data/raw_txt/MarmosetBreathingBehavior_Jan2021.xlsx'\n",
    "info_df = pd.read_excel(info_dir, sheet_name='Master')\n",
    "\n",
    "folder = '/Users/bishopmn/Documents/Projects/Marm_breathing/Raw_data/smr_files/20201204/' # <----- Change this to where the smr files are\n",
    "output_dir = '/Users/bishopmn/Documents/Projects/Marm_breathing/processed_data/'\n",
    "os.chdir(folder)\n",
    "\n",
    "# Load baseline and challenge files\n",
    "file_list = sorted([i for i in os.listdir(folder) if 'smr' in i])\n",
    "EPOCH_LEN = 59.9\n",
    "    \n",
    "# Make file writer\n",
    "timestr = time.strftime(\"%Y%m%d-\")\n",
    "master_filename = timestr + 'Chudasama' + '_resp.xlsx'\n",
    "\n",
    "global writer \n",
    "writer = pd.ExcelWriter(output_dir+master_filename, engine='xlsxwriter')\n",
    "\n",
    "# Features\n",
    "cols = ['Animal','RSP_Rate_Mean','RSP_Amplitude_Mean',\n",
    "        'Ti', 'Te', 'Ti-Te_Ratio','Resp_Drive','Ve',\n",
    "        'Apnea_time','Apnea_rate','Sniff_time','Sniff_rate',\n",
    "        'RRV_SD1','RRV_SD2']\n",
    "# events\n",
    "events_dict = {\n",
    "    'challenge':{}\n",
    "}\n",
    "for event, dictionary in events_dict.items():\n",
    "    # instantiate dictionaries that will be filled by file_processor\n",
    "    events_dict[event]['pre_'+str(event)] = {key:[] for key in cols}\n",
    "    events_dict[event][event] = {key:[] for key in cols}\n",
    "    if event == 'challenge': \n",
    "        events_dict[event]['post'+event] = {key:[] for key in cols}\n",
    "        \n",
    "#Process\n",
    "for file in file_list:\n",
    "    print(\"Processing: \", file)\n",
    "    file_processor(file, events_dict, info_df)\n",
    "\n",
    "print('Writing to excel')\n",
    "for key, item in events_dict.items():\n",
    "    for key2, item2 in item.items():\n",
    "        df = pd.DataFrame(item2)\n",
    "        df.to_excel(writer, sheet_name = key2)\n",
    "\n",
    "writer.save()\n",
    "print(master_filename, ' Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amber\n",
      "8333.333333333334\n",
      "CO2FAmbepre_challengeepochs\n"
     ]
    }
   ],
   "source": [
    "sample_file = 'Amber_CO2_Oct2020.smr'\n",
    "sample_sig = file_processor(sample_file, events_dict, info_df, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980.3921568627452\n"
     ]
    }
   ],
   "source": [
    "# Read in raw files\n",
    "reader = Spike2IO(sample_file)\n",
    "# Open block to select segment to be read\n",
    "block = reader.read(lazy=False)[0]\n",
    "raw_signal_vals = np.asarray(block.segments[0].analogsignals[1])\n",
    "flat_sig = raw_signal_vals[:,0]\n",
    "sampling_rate = block.segments[0].analogsignals[1].sampling_rate.item()\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
